---
title: "Evaluation of the probability of causation approach for lung cancer: Scoping review"
subtitle: "Search strategy construction"
author: 
  - name: Javier Mancilla Galindo
    affiliation: Institute for Risk Assessment Sciences, Utrecht University, Utrecht, The Netherlands
    orcid: 0000-0002-0718-467X
    email: j.mancillagalindo@uu.nl
keywords: ["probability of causation", "assigned share", "lung cancer", "causality", "scoping review"]
date: today
execute: 
  echo: false
  warning: false
toc: true
toc-depth: 1
format:
  html:
    toc: true
  docx:
    toc: false
    reference-doc: ../docs/manuscript/template.docx
    link-citations: true
  pdf:
    toc: false
    documentclass: scrartcl
zotero: probability-of-causation
bibliography: ../docs/manuscript/references.bib
csl: ../docs/manuscript/american-medical-association.csl
editor: source
---

```{r}
#| label: directories
#| include: false

# Create directories for sub-folders  
inputfolder <- "../data/raw"
psfolder <- "../data/processed"
tempfolder <- "../data/temp"
figfolder <- "../results/output_figures"
tabfolder <- "../results/output_tables"

dir.create(inputfolder, showWarnings = FALSE)
dir.create(psfolder, showWarnings = FALSE)
dir.create(tempfolder, showWarnings = FALSE)
dir.create(figfolder, showWarnings = FALSE)
dir.create(tabfolder, showWarnings = FALSE)
```

```{r}
#| label: packages
#| include: false 

if (!require("pacman", quietly = TRUE)) {
  install.packages("pacman")
}

pacman::p_load(
  devtools,         # Used to install packages from GitHub.
  tidyverse,        # Used for basic data handling and visualization.
  readxl,           # Used to read excel files.
  overviewR,        # Used to check missing data.
  gt,               # Used to print html tables.  
  report            # Used to cite packages used in this session.   
)

pacman::p_load_gh("elizagrames/litsearchr")  # Used to develop and refine search strategy 

```

```{r}
naiveresults <- read_excel(
  path = paste0(psfolder, "/2024-12-03_search_PoC_Lung_Cancer_deduplicated.xlsx"),
  sheet = "2024-12-03_search_PoC_Lung"
)
```

```{r}
rakedkeywords <-
  litsearchr::extract_terms(
    text = paste(naiveresults$title, naiveresults$abstract),
    method = "fakerake",
    min_freq = 2,
    ngrams = TRUE,
    min_n = 2,
    language = "English"
  )
```

```{r}
all_keywords <- unique(rakedkeywords)

naivedfm <-
  litsearchr::create_dfm(
    elements = paste(naiveresults$title, naiveresults$abstract),
    features = all_keywords
  )

naivegraph <-
  litsearchr::create_network(
    search_dfm = naivedfm,
    min_studies = 2,
    min_occ = 2
  )
```

```{r}
cutoff <-
  litsearchr::find_cutoff(
    naivegraph,
    method = "changepoint",
    knot_num = 3
    )

reducedgraph <-
  litsearchr::reduce_graph(naivegraph, cutoff_strength = cutoff[1])

searchterms <- litsearchr::get_keywords(reducedgraph)

set.seed(2024)
sample(searchterms, 20)
```

```{r}
write.csv(searchterms, file = file.path(psfolder,"search_terms_manual_review.csv"))
```


```{r}
grouped_terms <- read_excel(
  path = paste0(psfolder, "/search_terms_manual_review.xlsx"),
  sheet = "search_terms_manual_review"
) %>% filter(group != "drop")
```

```{r}
grouped_terms %>% 
  group_by(group) %>% 
  summarise(n = n())
```

```{r}
source("scripts/search_terms.R")
```


```{r}
# Append terms from grouped_terms to the manually defined vectors
concept <- unique(c(concept, grouped_terms$term[grouped_terms$group == "concept"]))
occupational <- unique(c(occupational, grouped_terms$term[grouped_terms$group == "occupational"]))
population <- unique(c(population, grouped_terms$term[grouped_terms$group == "population"]))
lung <- unique(c(lung, grouped_terms$term[grouped_terms$group == "lung"]))
financial <- unique(c(financial, grouped_terms$term[grouped_terms$group == "financial"]))

mysearchterms <- list(
  concept = concept,
  population = population,
  occupational = occupational,
  lung = lung
)
```

```{r}
my_search <-
  litsearchr::write_search(
    groupdata = mysearchterms,
    languages = "English",
    stemming = FALSE,
    closure = "right",
    exactphrase = TRUE,
    writesearch = TRUE,
    directory = paste0(tempfolder,"/"),
    verbose = TRUE
  )

my_search
```


```{r}
grouped_terms %>% filter(group == "financial") %>% group_by(term) %>% pull(term)
```


{{< pagebreak >}}

# References

::: {#refs}
:::

{{< pagebreak >}}

# Session Information

```{r}
#| label: session
# remove clutter
session <- sessionInfo()
session$BLAS <- NULL
session$LAPACK <- NULL
session$loadedOnly <- NULL
# write log file
writeLines(
  capture.output(print(session, locale = FALSE)),
  paste0("sessions/",lubridate::today(), "_search_strategy.txt")
)                                   

session
```

# Package References

```{r}
#| output: asis
report::cite_packages(session)
```

```{r}
#| include: false

# Run this chunk if you wish to clear your environment and unload packages.

pacman::p_unload(negate = TRUE)

rm(list = ls())
```
